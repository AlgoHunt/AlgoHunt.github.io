<meta name="viewport" content="width=device-width, initial-scale=1.0">
<html>
  	<head>
	    <title>Lingzhi Li 李凌志 - Personal Website</title>
	    <script src='js/jquery-1.11.2.min.js'></script>
	    <link href='css/bootstrap.min.css' rel='stylesheet'>
	    <link href='css/homepage_style.css' rel='stylesheet'>
	    <script src='js/bootstrap.min.js'></script>
		
      <link href='css/font.css' rel='stylesheet' type='text/css'>
	</head>
	<body>
        <div id="main">
		<div id='header' class ='bg'>
	      	<div id='header-inner'>
		        <img src='llz.jpg' class='img-me'>
		        <div class='header-text'>
		          <div class='header-text-name'>
		            Lingzhi Li 李凌志
		          </div>
		          <div class='header-text-email'>
		            lilingzhi at pku dot edu dot cn
		          </div>
		        </div>
	    	</div>
    	</div>
    	<div class='container'>
      		<div class='col-xs-12'>

        	<div class='row about'>
			<p>
			I am currently an algorithm expert in Damo Academic at Alibaba Group. Before that, I obtain my M.S and B.S degrees from Peking University and Beijing Jiaotong University, respectively.   During my internship at MSRA, I am fortunate to collaborate closely with <a href="https://jianminbao.github.io/", target="_blank">jianmin bao</a>, <a href="https://www.microsoft.com/en-us/research/people/haya/", target="_blank">Hao Yang</a>, <a href="https://www.microsoft.com/en-us/research/people/doch/", target="_blank">Dong Chen</a>, <a href="https://www.microsoft.com/en-us/research/people/fangwen/", target="_blank">Fang Wen</a> and <a href="https://scholar.google.com/citations?user=h4kYmRYAAAAJ", target="_blank">Baining Guo</a>.  
			</p>
          <p> My research interests are in computer vision. I'm particularly interested in the areas of generative model, deepfake detection and neural radiance field. Some of my work are among the PaperDigest Most Influential Papers. I serve the reviewer of many top conferences (including CVPR, ICCV, ECCV, AAAI and NeurIPs) and top journals (TVCJ, IJCV, TIP, TMM). You can find my full cv <a target="_blank" href="Lingzhi_Li_Resueme.pdf"> here </a> <!-- <a target="_blank" href="cv_academic.pdf">english</a>/<a target="_blank" href="cv_chinese.pdf">中文</a>.</p>-->.
        </div>
	
	<div class='row'>
          <hr>
        </div>
			
	<div class='row vspace-top-small'>
         <h1>News</h1>
		
        </div>  
		<div>
		2023.7 &nbsp;1 Paper are accepted by ICCV 2023
		</div>
		<div>
		2023.6 &nbsp;1 Paper are accepted by TOG
		</div>
		<div>
		    2023.2 &nbsp;1 Paper are accepted by CVPR 2023
		</div>
		<div>
		    2022.9 &nbsp;1 Paper are accepted by Siggraph Asia'2022 Technical Communications
		</div>
		<div>
		    2022.9 &nbsp;1 Paper are accepted by NeurIPS'2022
		</div>
		<div>
		<font color="red">2020.9</font> &nbsp;Face X-ray has been applied in Microsoft's New Product <a target="_blank" href="https://blogs.microsoft.com/on-the-issues/2020/09/01/disinformation-deepfakes-newsguard-video-authenticator/"><b>Video Authenticator</b>
		</div>
			
		<div>
		<font color="red">2020.1</font> &nbsp;Face X-ray and FaceShifter has been covered by <a target="_blank" href="https://venturebeat.com/2020/01/06/microsoft-researchers-propose-face-swapping-ai-and-face-forgery-detector/"><b>venturebeat</b></a> and <a target="_blank" href="https://syncedreview.com/2020/01/06/microsoft-peking-university-faceshifter-high-fidelity-occlusion-aware-face-swapping/"><b>syncedreview</b></a> 
		</div>
		
		<div>
		2019.3 &nbsp;Our submission ranking the <a target="_blank" href="https://www.cityscapes-dataset.com/method-details/?submissionID=3707"><b>#3</b></a> (when submitting)in cityscapes benchmark 
		</div>
			
			
        <div class='row'>
          <hr>
        </div>


        <div class='row'>
          <h1>Publications</h1>
        </div>
		
		<div class='row vspace-top-small'>
	
			<div class='col-xs-2'>
				<img class="paper-image" src="images/4k-nerf.png">
			</div>
			<div class='col-xs-10'>
			  <div class='paper-title'>
				4K-NeRF: High Fidelity Neural Radiance Fields at Ultra High Resolutions 
			  </div>
			  <div class='paper-authors'>
				Zhongshu Wang, <b>Lingzhi Li</b>, Zhen Shen, Li Shen, Liefeng Bo
			  </div>
			  <div class='paper-venue'>
				Arxiv 
			  </div>
			  <div>
				<a target="_blank" href="https://arxiv.org/pdf/2212.04701.pdf">[paper]</a>
				<a target="_blank" href="https://github.com/frozoul/4K-NeRF">[code]</a>
				
			  </div>
			</div>
		</div>

		<div class='row vspace-top-small'>
	
			<div class='col-xs-2'>
				<img class="paper-image" src="images/vqrf.png">
			</div>
			<div class='col-xs-10'>
			  <div class='paper-title'>
				Compressing Volumetric Radiance Fields to 1 MB 
			  </div>
			  <div class='paper-authors'>
				<b>Lingzhi Li*</b>,Zhen Shen*, Zhongshu Wang, Li Shen, Liefeng Bo
			  </div>
			  <div class='paper-venue'>
				CVPR 2023 
			  </div>
			  <div>
				<a target="_blank" href="https://arxiv.org/pdf/2211.16386.pdf">[paper]</a>
				<a target="_blank" href="https://github.com/AlgoHunt/VQRF">[code]</a>
				
			  </div>
			</div>
		</div>

		<div class='row vspace-top-small'>
	
			<div class='col-xs-2'>
				<img class="paper-image" src="images/streamrf.png">
			</div>
			<div class='col-xs-10'>
			  <div class='paper-title'>
				Streaming Radiance Fields for 3D Video Synthesis
			  </div>
			  <div class='paper-authors'>
				<b>Lingzhi Li</b>,Zhen Shen, Zhongshu Wang, Li Shen, Ping Tan
			  </div>
			  <div class='paper-venue'>
				NeurIPS 2022 
			  </div>
			  <div>
				<a target="_blank" href="https://arxiv.org/pdf/2210.14831.pdf">[paper]</a>
				<a target="_blank" href="https://github.com/AlgoHunt/StreamRF">[code]</a>
				
			  </div>
			</div>
		</div>

		<div class='row vspace-top-small'>
	
			<div class='col-xs-2'>
				<img class="paper-image" src="images/your3demoji.png">
			</div>
			<div class='col-xs-10'>
			  <div class='paper-title'>
				Your3dEmoji: Creating Personalized Emojis via One-shot 3D-aware Cartoon Avatar Synthesis
			  </div>
			  <div class='paper-authors'>
				Shiyao Xu, <b>Lingzhi Li</b>, Li Shen, Yifang Men, Zhouhui Lian
			  </div>
			  <div class='paper-venue'>
				Siggraph Asia 2022 Technical Communication
			  </div>
			  <div>
				<a target="_blank" href=https://dl.acm.org/doi/abs/10.1145/3550340.3564220">[paper]</a>
				
			  </div>
			</div>
		</div>

        <div class='row vspace-top-small'>
	
			<div class='col-xs-2'>
				<img class="paper-image" src="images/faceshifter.jpg">
			</div>
			<div class='col-xs-10'>
			  <div class='paper-title'>
				FaceShifter: Towards High Fidelity And Occlusion Aware Face Swapping
			  </div>
			  <div class='paper-authors'>
				<b>Lingzhi Li</b>, Jianming Bao, Hao Yang, Dong Chen and Fang Wen
			  </div>
			  <div class='paper-venue'>
				CVPR 2020 <b>Oral</b> <font color="red">!</font>
			  </div>
			  <div>
			 
				<a target="_blank" href="https://arxiv.org/pdf/1912.13457.pdf">[paper]</a>
				<a target="_blank" href="videos/FaceShifterDemo1.mp4">[demo1]</a>
				<a target="_blank" href="videos/FaceShifterDemo2.mp4">[demo2]</a>
				<a target="_blank" href="https://lingzhili.com/FaceShifterPage/">[project page]</a> 
				<a target="_blank" href="https://lingzhili.com/FaceShifterPage/">[dataset]</a> 
			  </div>
			</div>
		</div>
		
		<div class='row vspace-top-small'>
			<div class='col-xs-2'>
				<img class="paper-image" src="images/facexray.jpg">
			</div>
			<div class='col-xs-10'>
			  <div class='paper-title'>
				Face X-ray for More General Face Forgery Detection
			  </div>
			  <div class='paper-authors'>
				<b>Lingzhi Li*</b>, Jianming Bao*, Ting Zhang, Hao Yang, Dong Chen, Fang Wen and Baining Guo
			  </div>
			  <div class='paper-venue'>
				CVPR 2020 <b>Oral</b> <font color="red">!</font>
			  </div>
			  <div>
				<a target="_blank" href="https://arxiv.org/pdf/1912.13458.pdf">[paper]</a>
				<a target="_blank" href="https://github.com/AlgoHunt/Face-Xray">[code]</a>
				
			  </div>
			</div>
			
		</div>	
			  
				
		
		<div class='row vspace-top-small'>
			<div class='col-xs-2'>
				<img class="paper-image" src="images/GGCF.jpg">
			</div>
			<div class='col-xs-10'>
			  <div class='paper-title'>
				Graph Guided Context Fusion for Semantic Segmentation
			  </div>
			  <div class='paper-authors'>
				<b>Lingzhi Li</b>, Hao Yang, Dong Chen and Fang Wen
			  </div>
			  <div class='paper-venue'>
				Technical Report
			  </div>
			  <div>
			   
				<a  target="_blank" href="pdf/Semantic_Segmentation_ICCV19.pdf">[paper]</a>
			  <!--
				<a target="_blank" href="bibs/neural_tog2018.txt">[bibtex]</a>
			  -->
	
				</div>	
			</div>
		</div>	
		
		
		<div class='row'>
          <hr>
        </div>

        
        <div class='row'>
          <h1>Experience</h1>
        </div>

        <div class='row vspace-top-small'>
          <div>
            <b>2020.7 ~ present: </b> &nbsp;&nbsp;Algorithm Expert in Alibaba Cloud.
          </div>
		
          <div>
            <b>2018.8 ~ 2020.6: </b> &nbsp;&nbsp;Research Intern in MSRA mentored by Dong Chen and Hao Yang.
          </div>
	  
        </div>

        <div class='row'>
          <hr>
        </div>
		
	
        <div class='row'>
          <h1>Awards and Honors</h1>
        </div>
        <div class='row vspace-top-small'>
	  <div>
          2020 Microsoft Research Asia Stars of Tomorrow (Award of Excellent Intern). 
          </div>
          <div>
          2018 <b>Jane Street</b> Electronic Trading Competition,  <a target="_blank" href="https://mp.weixin.qq.com/s?__biz=MzA4NzAyMzMxMA==&mid=2658649479&idx=1&sn=8c3e9dd913db21af5652a5891ce08190&chksm=8bbcae26bccb273081cf529f074ba78ad24f39f483267f2ae726ae26a9202154db8a3b09d85f&mpshare=1&scene=1&srcid=1030XgFdmjXMjGi82vJJXEuj&sharer_sharetime=1568426599291&sharer_shareid=fdbf1d45dc276ec1a04d6f363313a8b3&pass_ticket=nS6yl0nUc%2F%2BQw7zHkVLwzmj7THHsVuLV1MW8woxB2Kag5S1%2Fz2KQRIc9kk82jdsm#rd"><b>1st</b></a>
          </div>
          <div>
          2018 <b>Citadel</b> Data-Open Beijing,  <b>2nd</b>
          </div>
          <div>
          2018 Merit Student Awards
          </div>
          <div>
          2017 WWW 2018 Musical Genre Classification Challenge  5th/274
          </div>
        </div>
		

		
	<div class='row'>
          <hr>
        </div>
		
		<div class='counter'>
	     <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?t=tt&d=NZe7N8gh_Bs_V7P9Jja_wCmr8Acea2vEZqn4-rV46as&cl=ffffff&w=a"></script>
		</div>
      </div>
	  
    </div>
	
	</div>
	</body>
</html>
